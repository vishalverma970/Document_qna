{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712a0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958e3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513aaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"/Users/vishalverma/Vishal/Learning - Fractal/GenAi/docs/Doc A - MDL-785_0.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d964a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2202c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1,vec2):\n",
    "    return np.dot(vec1,vec2)/(norm(vec1)*norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca53dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load document\n",
    "loader1 = PyMuPDFLoader(document_path)\n",
    "documents = loader1.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73424f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size = 1000,chunk_overlap = 10)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d735467",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = {'question' : \"What is the purpose of the act?\",\n",
    "            \"answer\" : \"the purpose of the act is to establish regulations and guidelines for credit for reinsurance, including requirements for collateralization of unauthorized reinsurance recoverable and the establishment of trust funds as security for insureds, claimants, ceding insurers, assuming insurers, and the public. It also includes provisions for the control and distribution of funds by U.S. regulators and applies to all cessions under reinsurance agreements with an inception, anniversary, or renewal date not less than six months after the effective date of the act.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c21afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8da561",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af856232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishalverma/tensorflow/env/lib/python3.8/site-packages/langchain/llms/openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/vishalverma/tensorflow/env/lib/python3.8/site-packages/langchain/llms/openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "llm = OpenAI(model_name=model_name,temperature = 0.2)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d8c9429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of the act is to protect the interest of insureds, claimants, ceding insurers, assuming insurers, and the public generally, and to ensure adequate regulation of insurers and reinsurers and adequate protection for those to whom they owe obligations. It also mandates that upon the insolvency of a non-U.S. insurer or reinsurer that provides security to fund its U.S. obligations in accordance with this Act, the assets representing the security shall be maintained in the United States and claims shall be filed with and valued by the state insurance commissioner with regulatory oversight, and the assets shall be distributed, in accordance with the insurance laws of the state in which the trust is domiciled that are applicable to the liquidation of domestic U.S. insurance companies.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the purpose of the act?\"\n",
    "# prompt = f\"Make this answer simple : {query}\"\n",
    "answer = chain.run(input_documents=db.similarity_search(query), question=query)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99eba4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity : 0.8110518455505371\n"
     ]
    }
   ],
   "source": [
    "expected_ans_vector = sbert_model.encode(test_case['answer'])\n",
    "predicted_vectore = sbert_model.encode(answer)\n",
    "similarity = cosine_similarity(predicted_vectore,expected_ans_vector)\n",
    "print(f\"similarity : {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129a8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
